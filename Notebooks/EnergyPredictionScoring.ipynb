{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc3e4402",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWbXCGozBRNW",
      "metadata": {
        "id": "sWbXCGozBRNW"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kmxpysFu7zjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxpysFu7zjH",
        "outputId": "db2717d5-22be-4fa8-99fb-3f9ea90e7e1b"
      },
      "outputs": [],
      "source": [
        "# data elaboration functions\n",
        "import pandas as pd\n",
        "from six.moves import collections_abc\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# datetime functions\n",
        "import datetime as dt\n",
        "\n",
        "# file management functions\n",
        "import os\n",
        "import sys\n",
        "import opendatasets as od\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# plot functions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# data science functions\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# configuration file\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from Configuration.config import cfg_path\n",
        "\n",
        "# custom functions\n",
        "from Code.Plotting.plots import Plots\n",
        "from Code.Regressors.regressors import Regressors\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Scoring.train_test import TrainTest\n",
        "from Code.Scoring.train import Training\n",
        "from Code.Scoring.forecast import Forecasting\n",
        "from Code.Scoring.kpi import Kpi\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Utils.utils import Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc26b7b",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "458162d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#od.download(\"https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset/download\")\n",
        "root = Path(os.getcwd()).parent\n",
        "dataset_path = os.path.join(root, cfg_path.data_dir.input_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bb0e13",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "09358d6d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "      <th>holidays</th>\n",
              "      <th>day_off</th>\n",
              "      <th>surface</th>\n",
              "      <th>base_temperature</th>\n",
              "      <th>wd_mon</th>\n",
              "      <th>...</th>\n",
              "      <th>month_07</th>\n",
              "      <th>month_08</th>\n",
              "      <th>month_09</th>\n",
              "      <th>month_10</th>\n",
              "      <th>month_11</th>\n",
              "      <th>month_12</th>\n",
              "      <th>temperature</th>\n",
              "      <th>distance</th>\n",
              "      <th>DDC_temperature</th>\n",
              "      <th>DDH_temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>2015-11-02 00:00:00+00:00</td>\n",
              "      <td>3747176.0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>3.870603e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>891.487850</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17.333333</td>\n",
              "      <td>28.407896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>2015-11-02 00:00:00+00:00</td>\n",
              "      <td>2912040.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>2.593093e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1218.738383</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.226667</td>\n",
              "      <td>21.793645</td>\n",
              "      <td>6.226667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>21</td>\n",
              "      <td>2015-11-02 00:00:00+00:00</td>\n",
              "      <td>4779740.0</td>\n",
              "      <td>649.0</td>\n",
              "      <td>3.349616e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10985.292634</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.495833</td>\n",
              "      <td>11.902777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.504167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>22</td>\n",
              "      <td>2015-11-02 00:00:00+00:00</td>\n",
              "      <td>662180.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>3.668250e+05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7392.365415</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15.583333</td>\n",
              "      <td>23.726983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>2015-11-02 00:00:00+00:00</td>\n",
              "      <td>3488017.0</td>\n",
              "      <td>773.0</td>\n",
              "      <td>2.968195e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2201.924904</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.637500</td>\n",
              "      <td>16.135872</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.362500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    site_id                 timestamp     obs_id  forecast_id         value  \\\n",
              "1        13 2015-11-02 00:00:00+00:00  3747176.0        415.0  3.870603e+06   \n",
              "3        16 2015-11-02 00:00:00+00:00  2912040.0        524.0  2.593093e+06   \n",
              "11       21 2015-11-02 00:00:00+00:00  4779740.0        649.0  3.349616e+06   \n",
              "13       22 2015-11-02 00:00:00+00:00   662180.0        685.0  3.668250e+05   \n",
              "17       25 2015-11-02 00:00:00+00:00  3488017.0        773.0  2.968195e+06   \n",
              "\n",
              "    holidays  day_off       surface  base_temperature  wd_mon  ...  month_07  \\\n",
              "1          1        0    891.487850              18.0       1  ...         0   \n",
              "3          1        0   1218.738383              18.0       1  ...         0   \n",
              "11         1        0  10985.292634              18.0       1  ...         0   \n",
              "13         1        0   7392.365415              18.0       1  ...         0   \n",
              "17         1        0   2201.924904              18.0       1  ...         0   \n",
              "\n",
              "    month_08  month_09  month_10  month_11  month_12  temperature   distance  \\\n",
              "1          0         0         0         1         0    17.333333  28.407896   \n",
              "3          0         0         0         1         0    24.226667  21.793645   \n",
              "11         0         0         0         1         0     7.495833  11.902777   \n",
              "13         0         0         0         1         0    15.583333  23.726983   \n",
              "17         0         0         0         1         0     7.637500  16.135872   \n",
              "\n",
              "    DDC_temperature  DDH_temperature  \n",
              "1          0.000000         0.666667  \n",
              "3          6.226667         0.000000  \n",
              "11         0.000000        10.504167  \n",
              "13         0.000000         2.416667  \n",
              "17         0.000000        10.362500  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final = pd.read_pickle(os.path.join(root, cfg_path.data_dir.output_path, 'df_final.pkl'))\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5884738d",
      "metadata": {},
      "source": [
        "# Define model_01_thermal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23ed7fb",
      "metadata": {},
      "source": [
        "## Parameter setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a9a6af5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_models = {}\n",
        "dict_models['model_01_thermal'] = {}\n",
        "dict_models['model_01_thermal']['id'] = 'site_id'\n",
        "dict_models['model_01_thermal']['list_unique_id'] = ['site_id', 'timestamp']\n",
        "dict_models['model_01_thermal']['y'] = 'value'\n",
        "\n",
        "# If the following are ='', it will take the latest year as test set and the previous year as train set\n",
        "dict_models['model_01_thermal']['train_start_date'] = ''\n",
        "dict_models['model_01_thermal']['train_end_date'] = ''\n",
        "dict_models['model_01_thermal']['test_start_date'] = ''\n",
        "dict_models['model_01_thermal']['test_end_date'] = ''\n",
        "\n",
        "# Forecast scope is the length in days of the desired forecast\n",
        "dict_models['model_01_thermal']['forecast_scope'] = 730"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146e2f2d",
      "metadata": {},
      "source": [
        "## Regressors dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10f1fc4b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['site_id', 'timestamp', 'obs_id', 'forecast_id', 'value', 'holidays',\n",
              "       'day_off', 'surface', 'base_temperature', 'wd_mon', 'wd_tue', 'wd_wed',\n",
              "       'wd_thu', 'wd_fri', 'wd_sat', 'wd_sun', 'month_01', 'month_02',\n",
              "       'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08',\n",
              "       'month_09', 'month_10', 'month_11', 'month_12', 'temperature',\n",
              "       'distance', 'DDC_temperature', 'DDH_temperature'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Have a look at the available regressors\n",
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4be2b20d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile dictionary of regressors\n",
        "dict_regressors = {             \n",
        "    'list_temp': ['temperature'],\n",
        "    'holidays': ['holidays'],\n",
        "    'wd': ['wd_fri', 'wd_mon', 'wd_tue', 'wd_sat', 'wd_sun', 'wd_thu'],\n",
        "    'month': ['month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12'],\n",
        "    'additional_regressors': ['distance']}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ad21db",
      "metadata": {},
      "source": [
        "#### Interaction terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "14ab926f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add optional interaction terms\n",
        "dict_interactions = {'set_01': {'reg_list_01': 'list_temp', 'reg_list_02': 'month'}}\n",
        "for r in list(dict_interactions.keys()):\n",
        "    list_element = list(dict_interactions[r].keys())\n",
        "    if len(list_element)==2:\n",
        "        reg_list_01 = dict_interactions[r][list_element[0]] \n",
        "        reg_list_02 = dict_interactions[r][list_element[1]]\n",
        "        for i in dict_regressors[reg_list_01]:\n",
        "            for j in dict_regressors[reg_list_02]:\n",
        "                Regressors.create_interactions(df_final, i, j)\n",
        "    else:\n",
        "        print('Define model: list of elements in interactions is more than 2', list_element)\n",
        "\n",
        "list_interactions = list(df_final.filter(like='*').columns)\n",
        "for e in list_interactions:\n",
        "    dict_regressors['additional_regressors'].append(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6945c3d0",
      "metadata": {},
      "source": [
        "#### Non linear terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "39e6b24d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add optional non linear terms\n",
        "dict_non_linear_terms = {'set_01':{'temperature': 2}}\n",
        "for r in list(dict_non_linear_terms.keys()):\n",
        "    list_element = list(dict_non_linear_terms[r].keys())\n",
        "    for e in list_element:\n",
        "        if len(list_element)==1:\n",
        "            var = list(dict_non_linear_terms[r].keys())[0]\n",
        "            n = dict_non_linear_terms[r][e]\n",
        "            Regressors.create_non_linear_terms(df_final, var, n)\n",
        "        else:\n",
        "            print('Define model: list of elements in non linear terms is more than 1', r, list_element)\n",
        "        \n",
        "list_non_linear_terms = list(df_final.filter(like='^').columns)\n",
        "for e in list_non_linear_terms:\n",
        "    dict_regressors['additional_regressors'].append(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021524df",
      "metadata": {},
      "source": [
        "## Algorithms dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "37117f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define algorithms to test\n",
        "n_jobs = -1\n",
        "dict_algorithms = {}\n",
        "dict_algorithms['RF_Regressor'] = RandomForestRegressor(n_estimators=200, max_depth = 10, random_state =0, n_jobs=n_jobs)\n",
        "dict_algorithms['LR_Regressor'] = LinearRegression(n_jobs=n_jobs)\n",
        "dict_algorithms['XGB_Regressor'] = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.5,\n",
        "                                max_depth = 5, alpha = 10, n_estimators = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217e2ff3",
      "metadata": {},
      "source": [
        "## Addind regressors and algorithms to model dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "04ac8962",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_models is the following: {'model_01_thermal': {'id': 'site_id', 'list_unique_id': ['site_id', 'timestamp'], 'y': 'value', 'train_start_date': '', 'train_end_date': '', 'test_start_date': '', 'test_end_date': '', 'forecast_scope': 730, 'regressors': {'list_temp': ['temperature'], 'holidays': ['holidays'], 'wd': ['wd_fri', 'wd_mon', 'wd_tue', 'wd_sat', 'wd_sun', 'wd_thu'], 'month': ['month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12'], 'additional_regressors': ['distance', 'temperature*month_01', 'temperature*month_02', 'temperature*month_03', 'temperature*month_04', 'temperature*month_05', 'temperature*month_07', 'temperature*month_08', 'temperature*month_09', 'temperature*month_10', 'temperature*month_11', 'temperature*month_12', 'temperature^2']}, 'algorithms': {'RF_Regressor': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=200, n_jobs=-1, oob_score=False,\n",
            "                      random_state=0, verbose=0, warm_start=False), 'LR_Regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), 'XGB_Regressor': XGBRegressor(alpha=10, base_score=None, booster=None, colsample_bylevel=None,\n",
            "             colsample_bynode=None, colsample_bytree=0.3, gamma=None,\n",
            "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
            "             learning_rate=0.5, max_delta_step=None, max_depth=5,\n",
            "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "             n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
            "             objective='reg:squarederror', random_state=None, reg_alpha=None,\n",
            "             reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
            "             tree_method=None, validate_parameters=None, verbosity=None)}}}\n"
          ]
        }
      ],
      "source": [
        "dict_models['model_01_thermal']['regressors'] = dict_regressors\n",
        "dict_models['model_01_thermal']['algorithms'] = dict_algorithms\n",
        "print('dict_models is the following:', dict_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SnZLgs7EAatB",
      "metadata": {
        "id": "SnZLgs7EAatB"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01cc7822",
      "metadata": {},
      "source": [
        "### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7E5fWofhAZKe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7E5fWofhAZKe",
        "outputId": "184c426a-9a85-48ec-98f9-6cbb39684b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "date_var = Utils.find_date(df_final)\n",
        "list_unique_id = dict_models['model_01_thermal']['list_unique_id']\n",
        "id = dict_models['model_01_thermal']['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8feed5d5",
      "metadata": {},
      "source": [
        "### Site stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b85e4455",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SitesIds with most samples [22, 49, 42, 25, 33]\n"
          ]
        }
      ],
      "source": [
        "site_stats = Scoring.stats_per_site(df_final, id, date_var)\n",
        "\n",
        "# Selecting Sites with most samples\n",
        "top5_sites = site_stats.iloc[:5][id]\n",
        "print(\"SitesIds with most samples\", top5_sites.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037e984b",
      "metadata": {},
      "source": [
        "### Training dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bdR2WHnTiaUa",
      "metadata": {
        "id": "bdR2WHnTiaUa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual id list: [22, 25, 33, 42, 49]\n",
            "Actual regressors available: ['forecast_id', 'day_off', 'month_03', 'month_05', 'distance', 'surface', 'temperature*month_02', 'month_12', 'value', 'month_04', 'month_08', 'wd_sun', 'temperature*month_04', 'temperature*month_05', 'wd_wed', 'temperature*month_10', 'obs_id', 'holidays', 'month_07', 'wd_thu', 'month_10', 'month_02', 'month_11', 'temperature*month_12', 'wd_tue', 'wd_fri', 'temperature*month_03', 'month_01', 'month_06', 'temperature^2', 'temperature*month_01', 'DDH_temperature', 'temperature*month_11', 'temperature*month_08', 'month_09', 'base_temperature', 'wd_mon', 'temperature*month_07', 'temperature*month_09', 'wd_sat', 'DDC_temperature', 'temperature']\n"
          ]
        }
      ],
      "source": [
        "df = df_final.loc[(df_final[id].isin(top5_sites)), ]\n",
        "print('Actual id list:', list(df[id].unique()))\n",
        "print('Actual regressors available:', list(set(list(df.columns)) - set(list_unique_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258e375b",
      "metadata": {},
      "source": [
        "# Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8ffb286c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forecasting with model model_01_thermal\n",
            "Actual regressors used in model: model_01_thermal ['temperature', 'holidays', 'wd_fri', 'wd_mon', 'wd_tue', 'wd_sat', 'wd_sun', 'wd_thu', 'month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12', 'distance', 'temperature*month_01', 'temperature*month_02', 'temperature*month_03', 'temperature*month_04', 'temperature*month_05', 'temperature*month_07', 'temperature*month_08', 'temperature*month_09', 'temperature*month_10', 'temperature*month_11', 'temperature*month_12', 'temperature^2']\n",
            "Forecasting site_id 22\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Train start date is 2015-11-02 00:00:00\n",
            "Train end date is 2016-11-03 00:00:00\n",
            "Train shape before removing nan is 336\n",
            "Min date AFTER removing nan is 2015-11-02 00:00:00\n",
            "Max date AFTER removing nan is 2016-11-03 00:00:00\n",
            "Shape AFTER removing nan is 336\n",
            "find_date, date_col found: ['timestamp']\n",
            "Test start date is 2016-11-04 00:00:00\n",
            "Test end date is 2017-11-04 00:00:00\n",
            "kpi for model RF_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model LR_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model XGB_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "site_id 22 forecasting completed with model model_01_thermal\n",
            "Forecasting site_id 25\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Train start date is 2015-11-02 00:00:00\n",
            "Train end date is 2016-11-03 00:00:00\n",
            "Train shape before removing nan is 338\n",
            "Min date AFTER removing nan is 2015-11-02 00:00:00\n",
            "Max date AFTER removing nan is 2016-11-03 00:00:00\n",
            "Shape AFTER removing nan is 338\n",
            "find_date, date_col found: ['timestamp']\n",
            "Test start date is 2016-11-04 00:00:00\n",
            "Test end date is 2017-11-04 00:00:00\n",
            "kpi for model RF_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model LR_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model XGB_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "site_id 25 forecasting completed with model model_01_thermal\n",
            "Forecasting site_id 33\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Train start date is 2015-11-02 00:00:00\n",
            "Train end date is 2016-11-03 00:00:00\n",
            "Train shape before removing nan is 338\n",
            "Min date AFTER removing nan is 2015-11-02 00:00:00\n",
            "Max date AFTER removing nan is 2016-11-03 00:00:00\n",
            "Shape AFTER removing nan is 338\n",
            "find_date, date_col found: ['timestamp']\n",
            "Test start date is 2016-11-04 00:00:00\n",
            "Test end date is 2017-11-04 00:00:00\n",
            "kpi for model RF_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model LR_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model XGB_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "site_id 33 forecasting completed with model model_01_thermal\n",
            "Forecasting site_id 42\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Train start date is 2015-11-02 00:00:00\n",
            "Train end date is 2016-11-03 00:00:00\n",
            "Train shape before removing nan is 319\n",
            "Min date AFTER removing nan is 2015-11-02 00:00:00\n",
            "Max date AFTER removing nan is 2016-11-03 00:00:00\n",
            "Shape AFTER removing nan is 319\n",
            "find_date, date_col found: ['timestamp']\n",
            "Test start date is 2016-11-04 00:00:00\n",
            "Test end date is 2017-11-04 00:00:00\n",
            "kpi for model RF_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model LR_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model XGB_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "site_id 42 forecasting completed with model model_01_thermal\n",
            "Forecasting site_id 49\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Train start date is 2015-11-02 00:00:00\n",
            "Train end date is 2016-11-03 00:00:00\n",
            "Train shape before removing nan is 321\n",
            "Min date AFTER removing nan is 2015-11-19 00:00:00\n",
            "Max date AFTER removing nan is 2016-11-03 00:00:00\n",
            "Shape AFTER removing nan is 321\n",
            "find_date, date_col found: ['timestamp']\n",
            "Test start date is 2016-11-04 00:00:00\n",
            "Test end date is 2017-11-04 00:00:00\n",
            "kpi for model RF_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model LR_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "kpi for model XGB_Regressor\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Training\n",
            "Training completed\n",
            "find_date, date_col found: ['timestamp']\n",
            "Forecasting\n",
            "Forecasting completed\n",
            "site_id 49 forecasting completed with model model_01_thermal\n"
          ]
        }
      ],
      "source": [
        "dict_results = {}\n",
        "for m in list(dict_models.keys()):\n",
        "    print('Forecasting with model', m)\n",
        "    dict_results[m] = {}\n",
        "    \n",
        "    # Get dict of algorithms\n",
        "    dict_algorithms = dict_models[m]['algorithms']    \n",
        "    \n",
        "    # Get list of algorithms\n",
        "    list_regressors = []\n",
        "    for reg in list(dict_models[m]['regressors'].keys()):\n",
        "        list_regressors = list_regressors + dict_models[m]['regressors'][reg]\n",
        "        \n",
        "    print('Actual regressors used in model:', m, list_regressors)\n",
        "        \n",
        "    # Define columns to keep: list unique id, y and list of regressors\n",
        "    list_unique_id = dict_models[m]['list_unique_id'] \n",
        "    y = dict_models[m]['y']\n",
        "    id = dict_models[m]['id']\n",
        "    cols_to_keep = dict_models[m]['list_unique_id'] + [y] + list_regressors \n",
        "    \n",
        "    # Define train and test set\n",
        "    train_start_date = dict_models[m]['train_start_date']\n",
        "    train_end_date = dict_models[m]['train_end_date']\n",
        "    test_start_date = dict_models[m]['test_start_date']\n",
        "    test_end_date = dict_models[m]['test_end_date']\n",
        "    forecast_scope = dict_models[m]['forecast_scope']\n",
        "\n",
        "    for s in list(df[id].unique()):\n",
        "        print('Forecasting', id, s)\n",
        "        dict_results[m][s] = {}\n",
        "        df_sliced = df.loc[df[id]==s, cols_to_keep].copy()\n",
        "        \n",
        "        # Adding train and test set dates\n",
        "        dict_train_test_set = TrainTest.define_train_test_set_dates(df_sliced, train_start_date, train_end_date, test_start_date, test_end_date)\n",
        "        \n",
        "        test_end_date = dict_train_test_set['test_end_date']\n",
        "        test_start_date = dict_train_test_set['test_start_date']\n",
        "\n",
        "        train_start_date = dict_train_test_set['train_start_date']\n",
        "        train_end_date = dict_train_test_set['train_end_date']\n",
        "        \n",
        "        # Scoring\n",
        "        try:\n",
        "            dict_train = TrainTest.def_train(df_sliced, y, list_unique_id, train_start_date, train_end_date)\n",
        "            dict_test = TrainTest.def_test(df_sliced, y, list_unique_id, test_start_date, test_end_date, forecast_scope)\n",
        "            best_algorithm = Scoring.find_best_algorithm(y, dict_train, dict_test, dict_algorithms)\n",
        "            trained_model = Training.train(dict_train, dict_algorithms[best_algorithm])\n",
        "            forecasted_model = Forecasting.forecast(dict_test, trained_model)\n",
        "            dict_results[m][s] = {'best_algorithm': best_algorithm, 'historical_data': dict_train['historical_data'], 'forecast': forecasted_model['df_fcst'], 'train_start_date': dict_train['train_start_date'], 'train_end_date': dict_train['train_end_date'], 'test_start_date': dict_test['test_start_date'], 'test_end_date': dict_test['test_end_date']}\n",
        "            print(id, s, 'forecasting completed with model', m)\n",
        "        except ValueError as e:\n",
        "            raise Exception(id, s, 'could not be forecasted', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dWZkD8v6RLwk",
      "metadata": {
        "id": "dWZkD8v6RLwk"
      },
      "source": [
        "# Finalize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cbacdeb",
      "metadata": {},
      "source": [
        "### Create csv as per input format of PowerBI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "060959d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing PBI for site_id 22\n",
            "Preparing PBI for site_id 25\n",
            "Preparing PBI for site_id 33\n",
            "Preparing PBI for site_id 42\n",
            "Preparing PBI for site_id 49\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "      <th>fcst</th>\n",
              "      <th>site_id</th>\n",
              "      <th>model</th>\n",
              "      <th>best_algorithm</th>\n",
              "      <th>train_start_date</th>\n",
              "      <th>train_end_date</th>\n",
              "      <th>test_start_date</th>\n",
              "      <th>test_end_date</th>\n",
              "      <th>energy_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>3.668250e+05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>model_01_thermal</td>\n",
              "      <td>LR_Regressor</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>2017-11-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-11-03</td>\n",
              "      <td>2.454051e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>model_01_thermal</td>\n",
              "      <td>LR_Regressor</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>2017-11-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-11-04</td>\n",
              "      <td>1.673775e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>model_01_thermal</td>\n",
              "      <td>LR_Regressor</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>2017-11-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-11-05</td>\n",
              "      <td>2.509700e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>model_01_thermal</td>\n",
              "      <td>LR_Regressor</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>2017-11-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-11-06</td>\n",
              "      <td>2.899576e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>model_01_thermal</td>\n",
              "      <td>LR_Regressor</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>2017-11-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   timestamp         value  fcst  site_id             model best_algorithm  \\\n",
              "0 2015-11-02  3.668250e+05   NaN       22  model_01_thermal   LR_Regressor   \n",
              "1 2015-11-03  2.454051e+06   NaN       22  model_01_thermal   LR_Regressor   \n",
              "2 2015-11-04  1.673775e+06   NaN       22  model_01_thermal   LR_Regressor   \n",
              "3 2015-11-05  2.509700e+06   NaN       22  model_01_thermal   LR_Regressor   \n",
              "4 2015-11-06  2.899576e+06   NaN       22  model_01_thermal   LR_Regressor   \n",
              "\n",
              "  train_start_date train_end_date test_start_date test_end_date  energy_diff  \n",
              "0       2015-11-02     2016-11-03      2016-11-04    2017-11-04          NaN  \n",
              "1       2015-11-02     2016-11-03      2016-11-04    2017-11-04          NaN  \n",
              "2       2015-11-02     2016-11-03      2016-11-04    2017-11-04          NaN  \n",
              "3       2015-11-02     2016-11-03      2016-11-04    2017-11-04          NaN  \n",
              "4       2015-11-02     2016-11-03      2016-11-04    2017-11-04          NaN  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pbi = pd.DataFrame({})\n",
        "for m in list(dict_results.keys()):\n",
        "    for s in list(dict_results[m].keys()):\n",
        "        print('Preparing PBI for', id, s)\n",
        "        df_historical_data = dict_results[m][s]['historical_data']\n",
        "        df_forecast = dict_results[m][s]['forecast']\n",
        "        df_merged = pd.merge(df_historical_data, df_forecast, on = date_var, how='outer', validate='1:1')\n",
        "        df_merged.loc[:, id] = s\n",
        "        df_merged.loc[:, 'model'] = m\n",
        "        df_merged.loc[:, 'best_algorithm'] = dict_results[m][s]['best_algorithm'] \n",
        "        df_merged.loc[:, 'train_start_date'] = dict_results[m][s]['train_start_date'] \n",
        "        df_merged.loc[:, 'train_end_date'] = dict_results[m][s]['train_end_date'] \n",
        "        df_merged.loc[:, 'test_start_date'] = dict_results[m][s]['test_start_date'] \n",
        "        df_merged.loc[:, 'test_end_date'] = dict_results[m][s]['test_end_date'] \n",
        "        df_pbi = pd.concat([df_pbi, df_merged], axis=0)\n",
        "        df_pbi.loc[:, 'energy_diff'] = df_pbi['fcst'] - df_pbi[y]\n",
        "    \n",
        "df_pbi.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1985040e",
      "metadata": {},
      "source": [
        "### Compute KPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "edad5b22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 371692.0\n",
            "MAPE: 0.82\n"
          ]
        }
      ],
      "source": [
        "df_pbi.loc[:, 'error'] = df_pbi['fcst'] - df_pbi[y]\n",
        "df_pbi.loc[:, 'absolute_error'] = abs(df_pbi['fcst'] - df_pbi[y])\n",
        "df_pbi.loc[:, 'absolute_percentage_error'] = abs(df_pbi['fcst'] - df_pbi[y])/df_pbi[y]\n",
        "\n",
        "print(\"MAE:\", round(df_pbi.loc[:, 'absolute_error'].mean(), 0))\n",
        "print(\"MAPE:\", round(df_pbi.loc[:, 'absolute_percentage_error'].mean(), 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nrSxU-r-CNz",
      "metadata": {
        "id": "_nrSxU-r-CNz"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "NeLJE3BeI52l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "NeLJE3BeI52l",
        "outputId": "55195d02-857a-4388-e135-6ca50a4ca0dc"
      },
      "outputs": [],
      "source": [
        "chart_title = 'Energy prediction'\n",
        "y = 'value'\n",
        "for s in list(df_pbi[id].unique()):\n",
        "    df_plot = df_pbi.loc[df_pbi[id]==s, ]\n",
        "    saving_name = str(id) + '_' + str(s) + '_energy_prediction'\n",
        "    plot = Plots.sliding_fcst_plot(df_plot, y, 'fcst', chart_title, kpi=True)\n",
        "    df_plot.to_csv(os.path.join(root, cfg_path.data_dir.output_path, saving_name + \".csv\"))\n",
        "    plot.write_html(os.path.join(root, cfg_path.data_dir.plot_path, saving_name + \".html\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XzJoCxhYKAXQ",
      "metadata": {
        "id": "XzJoCxhYKAXQ"
      },
      "source": [
        "# Conversion factors\n",
        "KGCO2 = 0.2453kg/KWh\n",
        "\n",
        "Pounds = $0.1189/KWh"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AbKOiffyAql8",
        "6YxUycDC9p0h"
      ],
      "name": "Analysis (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
