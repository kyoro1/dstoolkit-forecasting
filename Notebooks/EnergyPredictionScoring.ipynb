{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc3e4402",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWbXCGozBRNW",
      "metadata": {
        "id": "sWbXCGozBRNW"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kmxpysFu7zjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxpysFu7zjH",
        "outputId": "db2717d5-22be-4fa8-99fb-3f9ea90e7e1b"
      },
      "outputs": [],
      "source": [
        "# data elaboration functions\n",
        "import pandas as pd\n",
        "from six.moves import collections_abc\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# datetime functions\n",
        "import datetime as dt\n",
        "\n",
        "# file management functions\n",
        "import os\n",
        "import sys\n",
        "import opendatasets as od\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# plot functions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# data science functions\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# configuration file\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from Configuration.config import cfg_path\n",
        "\n",
        "# custom functions\n",
        "from Code.Plotting.plots import Plots\n",
        "from Code.Regressors.regressors import Regressors\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Scoring.train_test import TrainTest\n",
        "from Code.Scoring.train import Training\n",
        "from Code.Scoring.forecast import Forecasting\n",
        "from Code.Scoring.kpi import Kpi\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Utils.utils import Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc26b7b",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458162d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#od.download(\"https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset/download\")\n",
        "root = Path(os.getcwd()).parent\n",
        "dataset_path = os.path.join(root, cfg_path.data_dir.input_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bb0e13",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09358d6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = pd.read_pickle(os.path.join(root, cfg_path.data_dir.output_path, 'df_final.pkl'))\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5884738d",
      "metadata": {},
      "source": [
        "# Define model_01_thermal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23ed7fb",
      "metadata": {},
      "source": [
        "## Parameter setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a6af5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_models = {}\n",
        "dict_models['model_01_thermal'] = {}\n",
        "dict_models['model_01_thermal']['id'] = 'site_id'\n",
        "dict_models['model_01_thermal']['list_unique_id'] = ['site_id', 'timestamp']\n",
        "dict_models['model_01_thermal']['y'] = 'value'\n",
        "\n",
        "# If the following are ='', it will take the latest year as test set and the previous year as train set\n",
        "dict_models['model_01_thermal']['train_start_date'] = ''\n",
        "dict_models['model_01_thermal']['train_end_date'] = ''\n",
        "dict_models['model_01_thermal']['test_start_date'] = ''\n",
        "dict_models['model_01_thermal']['test_end_date'] = ''\n",
        "\n",
        "# Forecast scope is the length in days of the desired forecast\n",
        "dict_models['model_01_thermal']['forecast_scope'] = 730"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146e2f2d",
      "metadata": {},
      "source": [
        "## Regressors dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f1fc4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Have a look at the available regressors\n",
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be2b20d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile dictionary of regressors\n",
        "dict_regressors = {             \n",
        "    'list_temp': ['temperature'],\n",
        "    'holidays': ['holidays'],\n",
        "    'wd': ['wd_fri', 'wd_mon', 'wd_tue', 'wd_sat', 'wd_sun', 'wd_thu'],\n",
        "    'month': ['month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12'],\n",
        "    'additional_regressors': ['distance']}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ad21db",
      "metadata": {},
      "source": [
        "#### Interaction terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ab926f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add optional interaction terms\n",
        "dict_interactions = {'set_01': {'reg_list_01': 'list_temp', 'reg_list_02': 'month'}}\n",
        "for r in list(dict_interactions.keys()):\n",
        "    list_element = list(dict_interactions[r].keys())\n",
        "    if len(list_element)==2:\n",
        "        reg_list_01 = dict_interactions[r][list_element[0]] \n",
        "        reg_list_02 = dict_interactions[r][list_element[1]]\n",
        "        for i in dict_regressors[reg_list_01]:\n",
        "            for j in dict_regressors[reg_list_02]:\n",
        "                Regressors.create_interactions(df_final, i, j)\n",
        "    else:\n",
        "        print('Define model: list of elements in interactions is more than 2', list_element)\n",
        "\n",
        "list_interactions = list(df_final.filter(like='*').columns)\n",
        "for e in list_interactions:\n",
        "    dict_regressors['additional_regressors'].append(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6945c3d0",
      "metadata": {},
      "source": [
        "#### Non linear terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39e6b24d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add optional non linear terms\n",
        "dict_non_linear_terms = {'set_01':{'temperature': 2}}\n",
        "for r in list(dict_non_linear_terms.keys()):\n",
        "    list_element = list(dict_non_linear_terms[r].keys())\n",
        "    for e in list_element:\n",
        "        if len(list_element)==1:\n",
        "            var = list(dict_non_linear_terms[r].keys())[0]\n",
        "            n = dict_non_linear_terms[r][e]\n",
        "            Regressors.create_non_linear_terms(df_final, var, n)\n",
        "        else:\n",
        "            print('Define model: list of elements in non linear terms is more than 1', r, list_element)\n",
        "        \n",
        "list_non_linear_terms = list(df_final.filter(like='^').columns)\n",
        "for e in list_non_linear_terms:\n",
        "    dict_regressors['additional_regressors'].append(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021524df",
      "metadata": {},
      "source": [
        "## Algorithms dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37117f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define algorithms to test\n",
        "n_jobs = -1\n",
        "dict_algorithms = {}\n",
        "dict_algorithms['RF_Regressor'] = RandomForestRegressor(n_estimators=200, max_depth = 10, random_state =0, n_jobs=n_jobs)\n",
        "dict_algorithms['LR_Regressor'] = LinearRegression(n_jobs=n_jobs)\n",
        "dict_algorithms['XGB_Regressor'] = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.5,\n",
        "                                max_depth = 5, alpha = 10, n_estimators = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217e2ff3",
      "metadata": {},
      "source": [
        "## Addind regressors and algorithms to model dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ac8962",
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_models['model_01_thermal']['regressors'] = dict_regressors\n",
        "dict_models['model_01_thermal']['algorithms'] = dict_algorithms\n",
        "print('dict_models is the following:', dict_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SnZLgs7EAatB",
      "metadata": {
        "id": "SnZLgs7EAatB"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01cc7822",
      "metadata": {},
      "source": [
        "### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7E5fWofhAZKe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7E5fWofhAZKe",
        "outputId": "184c426a-9a85-48ec-98f9-6cbb39684b02"
      },
      "outputs": [],
      "source": [
        "date_var = Utils.find_date(df_final)\n",
        "list_unique_id = dict_models['model_01_thermal']['list_unique_id']\n",
        "id = dict_models['model_01_thermal']['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8feed5d5",
      "metadata": {},
      "source": [
        "### Site stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85e4455",
      "metadata": {},
      "outputs": [],
      "source": [
        "site_stats = Scoring.stats_per_site(df_final, id, date_var)\n",
        "\n",
        "# Selecting Sites with most samples\n",
        "top5_sites = site_stats.iloc[:5][id]\n",
        "print(\"SitesIds with most samples\", top5_sites.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037e984b",
      "metadata": {},
      "source": [
        "### Training dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdR2WHnTiaUa",
      "metadata": {
        "id": "bdR2WHnTiaUa"
      },
      "outputs": [],
      "source": [
        "df = df_final.loc[(df_final[id].isin(top5_sites)), ]\n",
        "print('Actual id list:', list(df[id].unique()))\n",
        "print('Actual regressors available:', list(set(list(df.columns)) - set(list_unique_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258e375b",
      "metadata": {},
      "source": [
        "# Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ffb286c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_results = {}\n",
        "for m in list(dict_models.keys()):\n",
        "    print('Forecasting with model', m)\n",
        "    dict_results[m] = {}\n",
        "    \n",
        "    # Get dict of algorithms\n",
        "    dict_algorithms = dict_models[m]['algorithms']    \n",
        "    \n",
        "    # Get list of algorithms\n",
        "    list_regressors = []\n",
        "    for reg in list(dict_models[m]['regressors'].keys()):\n",
        "        list_regressors = list_regressors + dict_models[m]['regressors'][reg]\n",
        "        \n",
        "    print('Actual regressors used in model:', m, list_regressors)\n",
        "        \n",
        "    # Define columns to keep: list unique id, y and list of regressors\n",
        "    list_unique_id = dict_models[m]['list_unique_id'] \n",
        "    y = dict_models[m]['y']\n",
        "    id = dict_models[m]['id']\n",
        "    cols_to_keep = dict_models[m]['list_unique_id'] + [y] + list_regressors \n",
        "    \n",
        "    # Define train and test set\n",
        "    train_start_date = dict_models[m]['train_start_date']\n",
        "    train_end_date = dict_models[m]['train_end_date']\n",
        "    test_start_date = dict_models[m]['test_start_date']\n",
        "    test_end_date = dict_models[m]['test_end_date']\n",
        "    forecast_scope = dict_models[m]['forecast_scope']\n",
        "\n",
        "    for s in list(df[id].unique()):\n",
        "        print('Forecasting', id, s)\n",
        "        dict_results[m][s] = {}\n",
        "        df_sliced = df.loc[df[id]==s, cols_to_keep].copy()\n",
        "        \n",
        "        # Adding train and test set dates\n",
        "        dict_train_test_set = TrainTest.define_train_test_set_dates(df_sliced, train_start_date, train_end_date, test_start_date, test_end_date)\n",
        "        \n",
        "        test_end_date = dict_train_test_set['test_end_date']\n",
        "        test_start_date = dict_train_test_set['test_start_date']\n",
        "\n",
        "        train_start_date = dict_train_test_set['train_start_date']\n",
        "        train_end_date = dict_train_test_set['train_end_date']\n",
        "        \n",
        "        # Scoring\n",
        "        try:\n",
        "            dict_train = TrainTest.def_train(df_sliced, y, list_unique_id, train_start_date, train_end_date)\n",
        "            dict_test = TrainTest.def_test(df_sliced, y, list_unique_id, test_start_date, test_end_date, forecast_scope)\n",
        "            best_algorithm = Scoring.find_best_algorithm(y, dict_train, dict_test, dict_algorithms)\n",
        "            trained_model = Training.train(dict_train, dict_algorithms[best_algorithm])\n",
        "            forecasted_model = Forecasting.forecast(dict_test, trained_model)\n",
        "            dict_results[m][s] = {'best_algorithm': best_algorithm, 'historical_data': dict_train['historical_data'], 'forecast': forecasted_model['df_fcst'], 'train_start_date': dict_train['train_start_date'], 'train_end_date': dict_train['train_end_date'], 'test_start_date': dict_test['test_start_date'], 'test_end_date': dict_test['test_end_date']}\n",
        "            print(id, s, 'forecasting completed with model', m)\n",
        "        except ValueError as e:\n",
        "            raise Exception(id, s, 'could not be forecasted', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dWZkD8v6RLwk",
      "metadata": {
        "id": "dWZkD8v6RLwk"
      },
      "source": [
        "# Finalize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cbacdeb",
      "metadata": {},
      "source": [
        "### Create csv as per input format of PowerBI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060959d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pbi = pd.DataFrame({})\n",
        "for m in list(dict_results.keys()):\n",
        "    for s in list(dict_results[m].keys()):\n",
        "        print('Preparing PBI for', id, s)\n",
        "        df_historical_data = dict_results[m][s]['historical_data']\n",
        "        df_forecast = dict_results[m][s]['forecast']\n",
        "        df_merged = pd.merge(df_historical_data, df_forecast, on = date_var, how='outer', validate='1:1')\n",
        "        df_merged.loc[:, id] = s\n",
        "        df_merged.loc[:, 'model'] = m\n",
        "        df_merged.loc[:, 'best_algorithm'] = dict_results[m][s]['best_algorithm'] \n",
        "        df_merged.loc[:, 'train_start_date'] = dict_results[m][s]['train_start_date'] \n",
        "        df_merged.loc[:, 'train_end_date'] = dict_results[m][s]['train_end_date'] \n",
        "        df_merged.loc[:, 'test_start_date'] = dict_results[m][s]['test_start_date'] \n",
        "        df_merged.loc[:, 'test_end_date'] = dict_results[m][s]['test_end_date'] \n",
        "        df_pbi = pd.concat([df_pbi, df_merged], axis=0)\n",
        "        df_pbi.loc[:, 'energy_diff'] = df_pbi['fcst'] - df_pbi[y]\n",
        "    \n",
        "df_pbi.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1985040e",
      "metadata": {},
      "source": [
        "### Compute KPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edad5b22",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pbi.loc[:, 'error'] = df_pbi['fcst'] - df_pbi[y]\n",
        "df_pbi.loc[:, 'absolute_error'] = abs(df_pbi['fcst'] - df_pbi[y])\n",
        "df_pbi.loc[:, 'absolute_percentage_error'] = abs(df_pbi['fcst'] - df_pbi[y])/df_pbi[y]\n",
        "\n",
        "print(\"MAE:\", round(df_pbi.loc[:, 'absolute_error'].mean(), 0))\n",
        "print(\"MAPE:\", round(df_pbi.loc[:, 'absolute_percentage_error'].mean(), 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nrSxU-r-CNz",
      "metadata": {
        "id": "_nrSxU-r-CNz"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NeLJE3BeI52l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "NeLJE3BeI52l",
        "outputId": "55195d02-857a-4388-e135-6ca50a4ca0dc"
      },
      "outputs": [],
      "source": [
        "chart_title = 'Energy prediction'\n",
        "y = 'value'\n",
        "for s in list(df_pbi[id].unique()):\n",
        "    df_plot = df_pbi.loc[df_pbi[id]==s, ]\n",
        "    saving_name = str(id) + '_' + str(s) + '_energy_prediction'\n",
        "    plot = Plots.sliding_fcst_plot(df_plot, y, 'fcst', chart_title, kpi=True)\n",
        "    df_plot.to_csv(os.path.join(root, cfg_path.data_dir.output_path, saving_name + \".csv\"))\n",
        "    plot.write_html(os.path.join(root, cfg_path.data_dir.plot_path, saving_name + \".html\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XzJoCxhYKAXQ",
      "metadata": {
        "id": "XzJoCxhYKAXQ"
      },
      "source": [
        "# Conversion factors\n",
        "KGCO2 = 0.2453kg/KWh\n",
        "\n",
        "Pounds = $0.1189/KWh"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AbKOiffyAql8",
        "6YxUycDC9p0h"
      ],
      "name": "Analysis (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
