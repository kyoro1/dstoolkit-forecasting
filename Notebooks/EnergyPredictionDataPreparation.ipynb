{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f6b03474",
      "metadata": {
        "id": "f6b03474"
      },
      "source": [
        "[Dataset](https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "BeB-5Vb54j22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeB-5Vb54j22",
        "outputId": "f350c6a5-c497-4570-c4cf-14f0a8f42153"
      },
      "outputs": [],
      "source": [
        "#!kaggle datasets download -d arashnic/building-sites-power-consumption-dataset\n",
        "#!unzip building-sites-power-consumption-dataset.zip -d ./dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc3e4402",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWbXCGozBRNW",
      "metadata": {
        "id": "sWbXCGozBRNW"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "kmxpysFu7zjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxpysFu7zjH",
        "outputId": "db2717d5-22be-4fa8-99fb-3f9ea90e7e1b"
      },
      "outputs": [],
      "source": [
        "# data elaboration functions\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# datetime functions\n",
        "import datetime as dt\n",
        "\n",
        "# file management functions\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# plot functions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# data science functions\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# configuration file\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from Configuration.config import cfg_path\n",
        "\n",
        "# custom functions\n",
        "from Code.Plotting.plots import Plots\n",
        "from Code.Regressors.regressors import Regressors\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Scoring.train_test import TrainTest\n",
        "from Code.Scoring.train import Training\n",
        "from Code.Scoring.forecast import Forecasting\n",
        "from Code.Scoring.kpi import Kpi\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Utils.utils import Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc26b7b",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "458162d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#od.download(\"https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset/download\")\n",
        "root = Path(os.getcwd()).parent\n",
        "dataset_path = os.path.join(root, cfg_path.data_dir.input_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Q-4BToWB7LC",
      "metadata": {
        "id": "4Q-4BToWB7LC"
      },
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e791425d",
      "metadata": {},
      "source": [
        "If you don't have specific holiday dataset, you can use the following general function by country that uses the holiday python package and adds to your dataframe a columns with a holiday dummy variable (0/1):\n",
        "\n",
        "    df = Regressors.add_holidays_by_country(df, date_var, country = 'France')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d7e24623",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e24623",
        "outputId": "30507a03-42e3-4f9e-8b2b-bccb623a06c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Holiday columns:  ['date', 'holiday', 'site_id']\n",
            "NaNs: 0\n",
            "Metadata columns:  ['site_id', 'surface', 'sampling', 'base_temperature', 'monday_is_day_off', 'tuesday_is_day_off', 'wednesday_is_day_off', 'thursday_is_day_off', 'friday_is_day_off', 'saturday_is_day_off', 'sunday_is_day_off']\n",
            "NaNs: 0\n",
            "Weather columns:  ['timestamp', 'temperature', 'distance', 'site_id']\n",
            "NaNs: 0\n",
            "Train columns:  ['obs_id', 'site_id', 'timestamp', 'forecast_id', 'value']\n",
            "NaNs: 86601\n"
          ]
        }
      ],
      "source": [
        "df_holidays = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-holidays.csv\"), sep=\";\", parse_dates=[\"Date\"])\n",
        "df_holidays = Utils.columns_camel_to_snake(df_holidays)\n",
        "print(\"Holiday columns: \", list(df_holidays.columns))\n",
        "print(\"NaNs:\", df_holidays.isna().sum().values.sum())\n",
        "\n",
        "df_metadata = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-metadata.csv\"), sep=\";\")\n",
        "df_metadata = Utils.columns_camel_to_snake(df_metadata)\n",
        "print(\"Metadata columns: \", list(df_metadata.columns))\n",
        "print(\"NaNs:\", df_metadata.isna().sum().values.sum())\n",
        "\n",
        "df_weather = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-weather.csv\"), sep=\";\", parse_dates=[\"Timestamp\"])\n",
        "df_weather = Utils.columns_camel_to_snake(df_weather)\n",
        "print(\"Weather columns: \", list(df_weather.columns))\n",
        "print(\"NaNs:\", df_weather.isna().sum().values.sum())\n",
        "\n",
        "df_train_data = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-training-data.csv\"), sep=\";\", parse_dates=[\"Timestamp\"])\n",
        "df_train_data = Utils.columns_camel_to_snake(df_train_data)\n",
        "print(\"Train columns: \", list(df_train_data.columns))\n",
        "print(\"NaNs:\", df_train_data.isna().sum().values.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ShqG6YJGmBk",
      "metadata": {
        "id": "1ShqG6YJGmBk"
      },
      "source": [
        "# Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23ed7fb",
      "metadata": {},
      "source": [
        "## Parameter setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0ddada30",
      "metadata": {},
      "outputs": [],
      "source": [
        "id = 'site_id'\n",
        "list_unique_id = ['site_id', 'timestamp']\n",
        "list_temp = ['temp']\n",
        "y = 'value'\n",
        "forecast_end_date = '2022-12-31'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08af66c3",
      "metadata": {},
      "source": [
        "## Plotting y series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "23685319",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "# Print available ids and choose which one to plot \n",
        "print(list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e669264",
      "metadata": {},
      "outputs": [],
      "source": [
        "list_ids_to_plot = [49, 12, 63, 44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "109aaf82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting id: 49 as 1 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 49\n",
            "Plotting id: 12 as 2 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 12\n",
            "Plotting id: 63 as 3 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 63\n",
            "Plotting id: 44 as 4 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 44\n"
          ]
        }
      ],
      "source": [
        "count = 1\n",
        "for i in list_ids_to_plot:\n",
        "    print('Plotting id:', i, 'as', count, 'of', len(list_ids_to_plot))\n",
        "    plot = Plots.sliding_line_plot(df_train_data, y, id, i, chart_title=\"\")\n",
        "    plot.write_html(os.path.join(root, cfg_path.data_dir.plot_path, id + '_' + str(i) + \".html\"))\n",
        "    count = count + 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0be27d0",
      "metadata": {},
      "source": [
        "## Dealing with NAs and aggregating at a chosen frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e88444e",
      "metadata": {},
      "source": [
        "Create a full time sequence on a chosen frequency and aggregate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26de9cc1",
      "metadata": {},
      "source": [
        "#### Consumption data (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "77429654",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "List ids: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_train_data\n",
        "df_train_data.head()\n",
        "date_var = Utils.find_date(df_train_data)\n",
        "print('List ids:', list(df_train_data[id].unique()))\n",
        "len(list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "815adfaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check_length_time_serie: could not infer frequency\n",
            "Expected length of sequence:      site_id   count                       min                       max  \\\n",
            "0          1     900 2014-09-03 00:00:00+00:00 2017-08-17 00:00:00+00:00   \n",
            "1          2   34704 2013-01-01 01:00:00+00:00 2017-09-23 00:00:00+00:00   \n",
            "2          3     360 2013-01-02 00:00:00+00:00 2013-12-27 00:00:00+00:00   \n",
            "3          5     964 2013-01-01 01:00:00+00:00 2013-01-11 01:45:00+00:00   \n",
            "4          6  140744 2013-01-01 01:00:00+00:00 2017-10-23 02:45:00+00:00   \n",
            "..       ...     ...                       ...                       ...   \n",
            "262      301    2250 2010-01-01 00:00:00+00:00 2017-08-21 00:00:00+00:00   \n",
            "263      302  223648 2009-12-31 12:15:00+00:00 2017-08-23 04:00:00+00:00   \n",
            "264      303    2250 2010-01-01 00:00:00+00:00 2017-08-21 00:00:00+00:00   \n",
            "265      304     450 2015-03-04 00:00:00+00:00 2016-07-25 00:00:00+00:00   \n",
            "266      305     964 2015-11-09 11:45:00+00:00 2015-11-19 12:30:00+00:00   \n",
            "\n",
            "                    td  freq  expected_obs  \n",
            "0   3090 days 08:45:00   NaN           NaN  \n",
            "1   3090 days 08:45:00   NaN           NaN  \n",
            "2   3090 days 08:45:00   NaN           NaN  \n",
            "3   3090 days 08:45:00   NaN           NaN  \n",
            "4   3090 days 08:45:00   NaN           NaN  \n",
            "..                 ...   ...           ...  \n",
            "262 3090 days 08:45:00   NaN           NaN  \n",
            "263 3090 days 08:45:00   NaN           NaN  \n",
            "264 3090 days 08:45:00   NaN           NaN  \n",
            "265 3090 days 08:45:00   NaN           NaN  \n",
            "266 3090 days 08:45:00   NaN           NaN  \n",
            "\n",
            "[267 rows x 7 columns]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>td</th>\n",
              "      <th>freq</th>\n",
              "      <th>expected_obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>900</td>\n",
              "      <td>2014-09-03 00:00:00+00:00</td>\n",
              "      <td>2017-08-17 00:00:00+00:00</td>\n",
              "      <td>3090 days 08:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>34704</td>\n",
              "      <td>2013-01-01 01:00:00+00:00</td>\n",
              "      <td>2017-09-23 00:00:00+00:00</td>\n",
              "      <td>3090 days 08:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>360</td>\n",
              "      <td>2013-01-02 00:00:00+00:00</td>\n",
              "      <td>2013-12-27 00:00:00+00:00</td>\n",
              "      <td>3090 days 08:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>964</td>\n",
              "      <td>2013-01-01 01:00:00+00:00</td>\n",
              "      <td>2013-01-11 01:45:00+00:00</td>\n",
              "      <td>3090 days 08:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>140744</td>\n",
              "      <td>2013-01-01 01:00:00+00:00</td>\n",
              "      <td>2017-10-23 02:45:00+00:00</td>\n",
              "      <td>3090 days 08:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id   count                       min                       max  \\\n",
              "0        1     900 2014-09-03 00:00:00+00:00 2017-08-17 00:00:00+00:00   \n",
              "1        2   34704 2013-01-01 01:00:00+00:00 2017-09-23 00:00:00+00:00   \n",
              "2        3     360 2013-01-02 00:00:00+00:00 2013-12-27 00:00:00+00:00   \n",
              "3        5     964 2013-01-01 01:00:00+00:00 2013-01-11 01:45:00+00:00   \n",
              "4        6  140744 2013-01-01 01:00:00+00:00 2017-10-23 02:45:00+00:00   \n",
              "\n",
              "                  td  freq  expected_obs  \n",
              "0 3090 days 08:45:00   NaN           NaN  \n",
              "1 3090 days 08:45:00   NaN           NaN  \n",
              "2 3090 days 08:45:00   NaN           NaN  \n",
              "3 3090 days 08:45:00   NaN           NaN  \n",
              "4 3090 days 08:45:00   NaN           NaN  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This function count the number of obs you should have if you had a full time sequence\n",
        "Utils.check_length_time_serie(df_train_data, date_var, index = id).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f711e287",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resample_data: variable obs_id\n",
            "resample_data: variable obs_id completed\n",
            "resample_data: variable forecast_id\n",
            "resample_data: variable forecast_id completed\n",
            "resample_data: variable value\n",
            "resample_data: variable value completed\n",
            "                       timestamp     obs_id  site_id  forecast_id  \\\n",
            "0      2015-11-02 00:00:00+00:00  3187477.0       42       1080.0   \n",
            "1      2015-11-03 00:00:00+00:00  1309542.0       42       1080.0   \n",
            "2      2015-11-04 00:00:00+00:00  6998589.0       42       1080.0   \n",
            "3      2015-11-05 00:00:00+00:00  5708558.0       42       1080.0   \n",
            "4      2015-11-06 00:00:00+00:00  6931527.0       42       1080.0   \n",
            "...                          ...        ...      ...          ...   \n",
            "188662 2015-02-12 00:00:00+00:00   954528.0       34        981.0   \n",
            "188663 2015-02-13 00:00:00+00:00  6319073.0       34        981.0   \n",
            "188664 2015-02-14 00:00:00+00:00   849485.0       34        981.0   \n",
            "188665 2015-02-15 00:00:00+00:00   141866.0       34        981.0   \n",
            "188666 2015-02-16 00:00:00+00:00  7593648.0       34        981.0   \n",
            "\n",
            "               value  \n",
            "0       6.370880e+05  \n",
            "1       1.006306e+06  \n",
            "2       1.008557e+06  \n",
            "3       1.017008e+06  \n",
            "4       1.028142e+06  \n",
            "...              ...  \n",
            "188662  2.165641e+04  \n",
            "188663  2.124533e+04  \n",
            "188664  1.011816e+04  \n",
            "188665  9.968675e+03  \n",
            "188666  1.181853e+04  \n",
            "\n",
            "[188667 rows x 5 columns]\n",
            "List ids after resampling: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "# Resampling function aggregates data in a dataframe with a chosen function, that can vary depending on the variable\n",
        "# i.e. temperatures when aggregated should be averaged, consumption should be summed, dummy variables should be pick as 'first'\n",
        "\n",
        "df_train_data[date_var].apply(lambda x: x.tz_localize(None))\n",
        "freq = dt.timedelta(days=1)\n",
        "dict_grouping = {'obs_id': 'first', 'forecast_id': 'first', 'value': 'sum'}\n",
        "df_resampled = Utils.resample_data(df_train_data, id, date_var, freq, dict_grouping)\n",
        "print('List ids after resampling:', list(df_resampled[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fecd0d49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding sequence to serie 42 as 1 of 267\n",
            "Adding sequence to serie 43 as 2 of 267\n",
            "Adding sequence to serie 40 as 3 of 267\n",
            "Adding sequence to serie 41 as 4 of 267\n",
            "Adding sequence to serie 63 as 5 of 267\n",
            "Adding sequence to serie 66 as 6 of 267\n",
            "Adding sequence to serie 67 as 7 of 267\n",
            "Adding sequence to serie 68 as 8 of 267\n",
            "Adding sequence to serie 64 as 9 of 267\n",
            "Adding sequence to serie 65 as 10 of 267\n",
            "Adding sequence to serie 69 as 11 of 267\n",
            "Adding sequence to serie 70 as 12 of 267\n",
            "Adding sequence to serie 72 as 13 of 267\n",
            "Adding sequence to serie 73 as 14 of 267\n",
            "Adding sequence to serie 115 as 15 of 267\n",
            "Adding sequence to serie 119 as 16 of 267\n",
            "Adding sequence to serie 116 as 17 of 267\n",
            "Adding sequence to serie 117 as 18 of 267\n",
            "Adding sequence to serie 118 as 19 of 267\n",
            "Adding sequence to serie 59 as 20 of 267\n",
            "Adding sequence to serie 60 as 21 of 267\n",
            "Adding sequence to serie 62 as 22 of 267\n",
            "Adding sequence to serie 61 as 23 of 267\n",
            "Adding sequence to serie 112 as 24 of 267\n",
            "Adding sequence to serie 109 as 25 of 267\n",
            "Adding sequence to serie 110 as 26 of 267\n",
            "Adding sequence to serie 111 as 27 of 267\n",
            "Adding sequence to serie 8 as 28 of 267\n",
            "Adding sequence to serie 9 as 29 of 267\n",
            "Adding sequence to serie 25 as 30 of 267\n",
            "Adding sequence to serie 26 as 31 of 267\n",
            "Adding sequence to serie 46 as 32 of 267\n",
            "Adding sequence to serie 47 as 33 of 267\n",
            "Adding sequence to serie 48 as 34 of 267\n",
            "Adding sequence to serie 49 as 35 of 267\n",
            "Adding sequence to serie 106 as 36 of 267\n",
            "Adding sequence to serie 107 as 37 of 267\n",
            "Adding sequence to serie 100 as 38 of 267\n",
            "Adding sequence to serie 101 as 39 of 267\n",
            "Adding sequence to serie 102 as 40 of 267\n",
            "Adding sequence to serie 105 as 41 of 267\n",
            "Adding sequence to serie 50 as 42 of 267\n",
            "Adding sequence to serie 51 as 43 of 267\n",
            "Adding sequence to serie 52 as 44 of 267\n",
            "Adding sequence to serie 53 as 45 of 267\n",
            "Adding sequence to serie 108 as 46 of 267\n",
            "Adding sequence to serie 14 as 47 of 267\n",
            "Adding sequence to serie 10 as 48 of 267\n",
            "Adding sequence to serie 11 as 49 of 267\n",
            "Adding sequence to serie 12 as 50 of 267\n",
            "Adding sequence to serie 13 as 51 of 267\n",
            "Adding sequence to serie 22 as 52 of 267\n",
            "Adding sequence to serie 23 as 53 of 267\n",
            "Adding sequence to serie 57 as 54 of 267\n",
            "Adding sequence to serie 54 as 55 of 267\n",
            "Adding sequence to serie 58 as 56 of 267\n",
            "Adding sequence to serie 93 as 57 of 267\n",
            "Adding sequence to serie 94 as 58 of 267\n",
            "Adding sequence to serie 96 as 59 of 267\n",
            "Adding sequence to serie 98 as 60 of 267\n",
            "Adding sequence to serie 99 as 61 of 267\n",
            "Adding sequence to serie 92 as 62 of 267\n",
            "Adding sequence to serie 44 as 63 of 267\n",
            "Adding sequence to serie 45 as 64 of 267\n",
            "Adding sequence to serie 88 as 65 of 267\n",
            "Adding sequence to serie 87 as 66 of 267\n",
            "Adding sequence to serie 89 as 67 of 267\n",
            "Adding sequence to serie 90 as 68 of 267\n",
            "Adding sequence to serie 84 as 69 of 267\n",
            "Adding sequence to serie 85 as 70 of 267\n",
            "Adding sequence to serie 86 as 71 of 267\n",
            "Adding sequence to serie 78 as 72 of 267\n",
            "Adding sequence to serie 83 as 73 of 267\n",
            "Adding sequence to serie 228 as 74 of 267\n",
            "Adding sequence to serie 222 as 75 of 267\n",
            "Adding sequence to serie 223 as 76 of 267\n",
            "Adding sequence to serie 224 as 77 of 267\n",
            "Adding sequence to serie 225 as 78 of 267\n",
            "Adding sequence to serie 226 as 79 of 267\n",
            "Adding sequence to serie 227 as 80 of 267\n",
            "Adding sequence to serie 215 as 81 of 267\n",
            "Adding sequence to serie 229 as 82 of 267\n",
            "Adding sequence to serie 230 as 83 of 267\n",
            "Adding sequence to serie 273 as 84 of 267\n",
            "Adding sequence to serie 276 as 85 of 267\n",
            "Adding sequence to serie 271 as 86 of 267\n",
            "Adding sequence to serie 274 as 87 of 267\n",
            "Adding sequence to serie 275 as 88 of 267\n",
            "Adding sequence to serie 272 as 89 of 267\n",
            "Adding sequence to serie 74 as 90 of 267\n",
            "Adding sequence to serie 77 as 91 of 267\n",
            "Adding sequence to serie 76 as 92 of 267\n",
            "Adding sequence to serie 75 as 93 of 267\n",
            "Adding sequence to serie 218 as 94 of 267\n",
            "Adding sequence to serie 219 as 95 of 267\n",
            "Adding sequence to serie 221 as 96 of 267\n",
            "Adding sequence to serie 233 as 97 of 267\n",
            "Adding sequence to serie 234 as 98 of 267\n",
            "Adding sequence to serie 269 as 99 of 267\n",
            "Adding sequence to serie 270 as 100 of 267\n",
            "Adding sequence to serie 235 as 101 of 267\n",
            "Adding sequence to serie 236 as 102 of 267\n",
            "Adding sequence to serie 237 as 103 of 267\n",
            "Adding sequence to serie 216 as 104 of 267\n",
            "Adding sequence to serie 217 as 105 of 267\n",
            "Adding sequence to serie 204 as 106 of 267\n",
            "Adding sequence to serie 209 as 107 of 267\n",
            "Adding sequence to serie 261 as 108 of 267\n",
            "Adding sequence to serie 262 as 109 of 267\n",
            "Adding sequence to serie 263 as 110 of 267\n",
            "Adding sequence to serie 264 as 111 of 267\n",
            "Adding sequence to serie 265 as 112 of 267\n",
            "Adding sequence to serie 266 as 113 of 267\n",
            "Adding sequence to serie 267 as 114 of 267\n",
            "Adding sequence to serie 268 as 115 of 267\n",
            "Adding sequence to serie 232 as 116 of 267\n",
            "Adding sequence to serie 212 as 117 of 267\n",
            "Adding sequence to serie 213 as 118 of 267\n",
            "Adding sequence to serie 205 as 119 of 267\n",
            "Adding sequence to serie 206 as 120 of 267\n",
            "Adding sequence to serie 207 as 121 of 267\n",
            "Adding sequence to serie 208 as 122 of 267\n",
            "Adding sequence to serie 210 as 123 of 267\n",
            "Adding sequence to serie 211 as 124 of 267\n",
            "Adding sequence to serie 260 as 125 of 267\n",
            "Adding sequence to serie 259 as 126 of 267\n",
            "Adding sequence to serie 255 as 127 of 267\n",
            "Adding sequence to serie 256 as 128 of 267\n",
            "Adding sequence to serie 257 as 129 of 267\n",
            "Adding sequence to serie 231 as 130 of 267\n",
            "Adding sequence to serie 252 as 131 of 267\n",
            "Adding sequence to serie 254 as 132 of 267\n",
            "Adding sequence to serie 250 as 133 of 267\n",
            "Adding sequence to serie 251 as 134 of 267\n",
            "Adding sequence to serie 253 as 135 of 267\n",
            "Adding sequence to serie 238 as 136 of 267\n",
            "Adding sequence to serie 239 as 137 of 267\n",
            "Adding sequence to serie 240 as 138 of 267\n",
            "Adding sequence to serie 241 as 139 of 267\n",
            "Adding sequence to serie 243 as 140 of 267\n",
            "Adding sequence to serie 244 as 141 of 267\n",
            "Adding sequence to serie 245 as 142 of 267\n",
            "Adding sequence to serie 246 as 143 of 267\n",
            "Adding sequence to serie 247 as 144 of 267\n",
            "Adding sequence to serie 248 as 145 of 267\n",
            "Adding sequence to serie 249 as 146 of 267\n",
            "Adding sequence to serie 123 as 147 of 267\n",
            "Adding sequence to serie 124 as 148 of 267\n",
            "Adding sequence to serie 125 as 149 of 267\n",
            "Adding sequence to serie 126 as 150 of 267\n",
            "Adding sequence to serie 121 as 151 of 267\n",
            "Adding sequence to serie 122 as 152 of 267\n",
            "Adding sequence to serie 120 as 153 of 267\n",
            "Adding sequence to serie 127 as 154 of 267\n",
            "Adding sequence to serie 128 as 155 of 267\n",
            "Adding sequence to serie 129 as 156 of 267\n",
            "Adding sequence to serie 200 as 157 of 267\n",
            "Adding sequence to serie 201 as 158 of 267\n",
            "Adding sequence to serie 199 as 159 of 267\n",
            "Adding sequence to serie 141 as 160 of 267\n",
            "Adding sequence to serie 140 as 161 of 267\n",
            "Adding sequence to serie 135 as 162 of 267\n",
            "Adding sequence to serie 136 as 163 of 267\n",
            "Adding sequence to serie 139 as 164 of 267\n",
            "Adding sequence to serie 202 as 165 of 267\n",
            "Adding sequence to serie 203 as 166 of 267\n",
            "Adding sequence to serie 151 as 167 of 267\n",
            "Adding sequence to serie 149 as 168 of 267\n",
            "Adding sequence to serie 152 as 169 of 267\n",
            "Adding sequence to serie 146 as 170 of 267\n",
            "Adding sequence to serie 148 as 171 of 267\n",
            "Adding sequence to serie 150 as 172 of 267\n",
            "Adding sequence to serie 190 as 173 of 267\n",
            "Adding sequence to serie 191 as 174 of 267\n",
            "Adding sequence to serie 19 as 175 of 267\n",
            "Adding sequence to serie 167 as 176 of 267\n",
            "Adding sequence to serie 162 as 177 of 267\n",
            "Adding sequence to serie 173 as 178 of 267\n",
            "Adding sequence to serie 171 as 179 of 267\n",
            "Adding sequence to serie 172 as 180 of 267\n",
            "Adding sequence to serie 169 as 181 of 267\n",
            "Adding sequence to serie 170 as 182 of 267\n",
            "Adding sequence to serie 163 as 183 of 267\n",
            "Adding sequence to serie 164 as 184 of 267\n",
            "Adding sequence to serie 165 as 185 of 267\n",
            "Adding sequence to serie 143 as 186 of 267\n",
            "Adding sequence to serie 145 as 187 of 267\n",
            "Adding sequence to serie 142 as 188 of 267\n",
            "Adding sequence to serie 197 as 189 of 267\n",
            "Adding sequence to serie 194 as 190 of 267\n",
            "Adding sequence to serie 195 as 191 of 267\n",
            "Adding sequence to serie 196 as 192 of 267\n",
            "Adding sequence to serie 192 as 193 of 267\n",
            "Adding sequence to serie 193 as 194 of 267\n",
            "Adding sequence to serie 160 as 195 of 267\n",
            "Adding sequence to serie 161 as 196 of 267\n",
            "Adding sequence to serie 153 as 197 of 267\n",
            "Adding sequence to serie 154 as 198 of 267\n",
            "Adding sequence to serie 155 as 199 of 267\n",
            "Adding sequence to serie 156 as 200 of 267\n",
            "Adding sequence to serie 157 as 201 of 267\n",
            "Adding sequence to serie 158 as 202 of 267\n",
            "Adding sequence to serie 159 as 203 of 267\n",
            "Adding sequence to serie 198 as 204 of 267\n",
            "Adding sequence to serie 175 as 205 of 267\n",
            "Adding sequence to serie 174 as 206 of 267\n",
            "Adding sequence to serie 183 as 207 of 267\n",
            "Adding sequence to serie 184 as 208 of 267\n",
            "Adding sequence to serie 185 as 209 of 267\n",
            "Adding sequence to serie 186 as 210 of 267\n",
            "Adding sequence to serie 189 as 211 of 267\n",
            "Adding sequence to serie 181 as 212 of 267\n",
            "Adding sequence to serie 182 as 213 of 267\n",
            "Adding sequence to serie 130 as 214 of 267\n",
            "Adding sequence to serie 131 as 215 of 267\n",
            "Adding sequence to serie 134 as 216 of 267\n",
            "Adding sequence to serie 132 as 217 of 267\n",
            "Adding sequence to serie 176 as 218 of 267\n",
            "Adding sequence to serie 180 as 219 of 267\n",
            "Adding sequence to serie 177 as 220 of 267\n",
            "Adding sequence to serie 178 as 221 of 267\n",
            "Adding sequence to serie 280 as 222 of 267\n",
            "Adding sequence to serie 281 as 223 of 267\n",
            "Adding sequence to serie 277 as 224 of 267\n",
            "Adding sequence to serie 287 as 225 of 267\n",
            "Adding sequence to serie 288 as 226 of 267\n",
            "Adding sequence to serie 278 as 227 of 267\n",
            "Adding sequence to serie 279 as 228 of 267\n",
            "Adding sequence to serie 294 as 229 of 267\n",
            "Adding sequence to serie 295 as 230 of 267\n",
            "Adding sequence to serie 292 as 231 of 267\n",
            "Adding sequence to serie 293 as 232 of 267\n",
            "Adding sequence to serie 289 as 233 of 267\n",
            "Adding sequence to serie 290 as 234 of 267\n",
            "Adding sequence to serie 286 as 235 of 267\n",
            "Adding sequence to serie 285 as 236 of 267\n",
            "Adding sequence to serie 284 as 237 of 267\n",
            "Adding sequence to serie 298 as 238 of 267\n",
            "Adding sequence to serie 299 as 239 of 267\n",
            "Adding sequence to serie 300 as 240 of 267\n",
            "Adding sequence to serie 283 as 241 of 267\n",
            "Adding sequence to serie 297 as 242 of 267\n",
            "Adding sequence to serie 302 as 243 of 267\n",
            "Adding sequence to serie 301 as 244 of 267\n",
            "Adding sequence to serie 303 as 245 of 267\n",
            "Adding sequence to serie 304 as 246 of 267\n",
            "Adding sequence to serie 305 as 247 of 267\n",
            "Adding sequence to serie 282 as 248 of 267\n",
            "Adding sequence to serie 6 as 249 of 267\n",
            "Adding sequence to serie 7 as 250 of 267\n",
            "Adding sequence to serie 15 as 251 of 267\n",
            "Adding sequence to serie 16 as 252 of 267\n",
            "Adding sequence to serie 2 as 253 of 267\n",
            "Adding sequence to serie 1 as 254 of 267\n",
            "Adding sequence to serie 3 as 255 of 267\n",
            "Adding sequence to serie 5 as 256 of 267\n",
            "Adding sequence to serie 20 as 257 of 267\n",
            "Adding sequence to serie 21 as 258 of 267\n",
            "Adding sequence to serie 17 as 259 of 267\n",
            "Adding sequence to serie 18 as 260 of 267\n",
            "Adding sequence to serie 27 as 261 of 267\n",
            "Adding sequence to serie 33 as 262 of 267\n",
            "Adding sequence to serie 29 as 263 of 267\n",
            "Adding sequence to serie 32 as 264 of 267\n",
            "Adding sequence to serie 38 as 265 of 267\n",
            "Adding sequence to serie 39 as 266 of 267\n",
            "Adding sequence to serie 34 as 267 of 267\n",
            "add_seq: there are NO duplicates in sequence\n",
            "add_seq: there are NO duplicates when adding sequence\n",
            "Total serie to forecast: 203988\n",
            "List ids after resampling and adding full time sequence: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "df_train_data = Utils.add_seq(df_resampled, date_var, serie = id, freq = freq, end_date='', start_date='')\n",
        "df_train_data.head()\n",
        "print('List ids after resampling and adding full time sequence:', list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed864ec4",
      "metadata": {},
      "source": [
        "#### Holidays data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "16f9715d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['date']\n"
          ]
        }
      ],
      "source": [
        "# df_holidays\n",
        "df_holidays.head()\n",
        "date_var = Utils.find_date(df_holidays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bdc5842b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check_length_time_serie: could not infer frequency\n",
            "Expected length of sequence:      site_id  count        min        max        td  freq  expected_obs\n",
            "0          1     62 2014-01-01 2018-01-01 3287 days   NaN           NaN\n",
            "1         12     25 2016-01-01 2017-12-25 3287 days   NaN           NaN\n",
            "2         13     52 2014-01-01 2017-12-25 3287 days   NaN           NaN\n",
            "3         14     56 2014-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "4         15     41 2014-01-01 2016-12-26 3287 days   NaN           NaN\n",
            "..       ...    ...        ...        ...       ...   ...           ...\n",
            "222      301    108 2009-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "223      302    108 2009-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "224      303    108 2009-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "225      304     33 2015-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "226      305     33 2015-01-01 2017-12-26 3287 days   NaN           NaN\n",
            "\n",
            "[227 rows x 7 columns]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>td</th>\n",
              "      <th>freq</th>\n",
              "      <th>expected_obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>3287 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>2017-12-25</td>\n",
              "      <td>3287 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>52</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>2017-12-25</td>\n",
              "      <td>3287 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>2017-12-26</td>\n",
              "      <td>3287 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>41</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>2016-12-26</td>\n",
              "      <td>3287 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  count        min        max        td  freq  expected_obs\n",
              "0        1     62 2014-01-01 2018-01-01 3287 days   NaN           NaN\n",
              "1       12     25 2016-01-01 2017-12-25 3287 days   NaN           NaN\n",
              "2       13     52 2014-01-01 2017-12-25 3287 days   NaN           NaN\n",
              "3       14     56 2014-01-01 2017-12-26 3287 days   NaN           NaN\n",
              "4       15     41 2014-01-01 2016-12-26 3287 days   NaN           NaN"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This function count the number of obs you should have if you had a full time sequence\n",
        "Utils.check_length_time_serie(df_holidays, date_var, index = id).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "667372aa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resample_data: variable holiday\n",
            "resample_data: variable holiday completed\n",
            "             date        holiday  site_id\n",
            "0      2014-01-01       New year        1\n",
            "1      2014-01-02           None        1\n",
            "2      2014-01-03           None        1\n",
            "3      2014-01-04           None        1\n",
            "4      2014-01-05           None        1\n",
            "...           ...            ...      ...\n",
            "257126 2017-12-21           None      288\n",
            "257127 2017-12-22           None      288\n",
            "257128 2017-12-23           None      288\n",
            "257129 2017-12-24           None      288\n",
            "257130 2017-12-25  Christmas Day      288\n",
            "\n",
            "[257131 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Resampling function aggregates data in a dataframe with a chosen function, that can vary depending on the variable\n",
        "# i.e. temperatures when aggregated should be averaged, consumption should be summed, dummy variables should be pick as 'first'\n",
        "\n",
        "df_holidays[date_var].apply(lambda x: x.tz_localize(None))\n",
        "freq = dt.timedelta(days=1)\n",
        "dict_grouping = {'holiday': 'first'}\n",
        "df_resampled = Utils.resample_data(df_holidays, id, date_var, freq, dict_grouping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f3841a36",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>holiday</th>\n",
              "      <th>site_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>New year</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date   holiday  site_id\n",
              "0 2014-01-01  New year        1\n",
              "1 2014-01-02      None        1\n",
              "2 2014-01-03      None        1\n",
              "3 2014-01-04      None        1\n",
              "4 2014-01-05      None        1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Regressor dataset do not need a full time sequence to check for NAs\n",
        "df_holidays = df_resampled.copy()\n",
        "df_holidays.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdc48fa",
      "metadata": {},
      "source": [
        "#### Additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6e08ec94",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>surface</th>\n",
              "      <th>sampling</th>\n",
              "      <th>base_temperature</th>\n",
              "      <th>monday_is_day_off</th>\n",
              "      <th>tuesday_is_day_off</th>\n",
              "      <th>wednesday_is_day_off</th>\n",
              "      <th>thursday_is_day_off</th>\n",
              "      <th>friday_is_day_off</th>\n",
              "      <th>saturday_is_day_off</th>\n",
              "      <th>sunday_is_day_off</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>207</td>\n",
              "      <td>7964.873347</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>15168.125971</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74</td>\n",
              "      <td>424.340663</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>239</td>\n",
              "      <td>1164.822636</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>274</td>\n",
              "      <td>1468.246690</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id       surface  sampling  base_temperature  monday_is_day_off  \\\n",
              "0      207   7964.873347      30.0              18.0              False   \n",
              "1        7  15168.125971      30.0              18.0              False   \n",
              "2       74    424.340663      15.0              18.0              False   \n",
              "3      239   1164.822636      15.0              18.0              False   \n",
              "4      274   1468.246690       5.0              18.0              False   \n",
              "\n",
              "   tuesday_is_day_off  wednesday_is_day_off  thursday_is_day_off  \\\n",
              "0               False                 False                False   \n",
              "1               False                 False                False   \n",
              "2               False                 False                False   \n",
              "3               False                 False                False   \n",
              "4               False                 False                False   \n",
              "\n",
              "   friday_is_day_off  saturday_is_day_off  sunday_is_day_off  \n",
              "0              False                 True               True  \n",
              "1              False                 True               True  \n",
              "2              False                 True               True  \n",
              "3              False                 True               True  \n",
              "4              False                 True               True  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_metadata \n",
        "# does not contain a time series, therefore it cannot be resampled and do not need a full time sequence to check for NAs\n",
        "df_metadata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca784d7",
      "metadata": {},
      "source": [
        "#### Weather data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7759c1a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "# df_weather\n",
        "df_weather.head()\n",
        "date_var = Utils.find_date(df_weather)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "835dfe3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check_length_time_serie: could not infer frequency\n",
            "Expected length of sequence:     site_id   count                       min                       max  \\\n",
            "0         2   95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "1         3   95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "2         4   95545 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "3         5   95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "4         6   95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "5         7   60945 2015-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "6         8   95545 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "7         9   75312 2013-01-01 13:00:00+00:00 2017-01-01 12:30:00+00:00   \n",
            "8        10   95545 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "9        12   21988 2015-12-31 16:00:00+00:00 2017-12-30 13:00:00+00:00   \n",
            "10       13    6121 2013-12-31 18:15:00+00:00 2017-12-13 23:00:00+00:00   \n",
            "11       16   29752 2013-12-31 18:15:00+00:00 2017-12-30 14:45:00+00:00   \n",
            "12       17      53 2014-05-14 21:53:00+00:00 2017-10-01 00:53:00+00:00   \n",
            "13       18      53 2014-05-14 21:53:00+00:00 2017-10-01 00:53:00+00:00   \n",
            "14       19   60784 2015-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
            "15       20   61376 2014-12-31 18:00:00+00:00 2017-12-30 15:15:00+00:00   \n",
            "16       21   33981 2014-01-01 01:00:00+00:00 2017-12-17 22:00:00+00:00   \n",
            "17       22  195970 2014-01-01 01:00:00+00:00 2017-12-30 22:30:00+00:00   \n",
            "18       23   59546 2014-01-01 01:00:00+00:00 2017-01-01 00:50:00+00:00   \n",
            "19       24   33981 2014-01-01 01:00:00+00:00 2017-12-17 22:00:00+00:00   \n",
            "20       25  130459 2014-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "21       26   54555 2014-01-01 01:58:00+00:00 2017-12-30 22:00:00+00:00   \n",
            "22       27   12514 2014-01-01 07:00:00+00:00 2017-12-30 15:50:00+00:00   \n",
            "23       28  140574 2014-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "24       29  208047 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "25       30  321083 2015-01-01 01:00:00+00:00 2017-12-30 22:30:00+00:00   \n",
            "26       32   69933 2015-01-01 01:00:00+00:00 2017-12-20 22:30:00+00:00   \n",
            "27       33   33981 2014-01-01 01:00:00+00:00 2017-12-17 22:00:00+00:00   \n",
            "28       34   74148 2015-01-01 01:00:00+00:00 2017-12-30 22:30:00+00:00   \n",
            "29       35   89352 2014-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "30       36  145396 2015-01-01 01:00:00+00:00 2017-12-30 22:30:00+00:00   \n",
            "31       37   59089 2015-01-01 02:00:00+00:00 2017-12-30 23:30:00+00:00   \n",
            "32       38  161023 2016-01-01 00:00:00+00:00 2017-12-30 21:20:00+00:00   \n",
            "33       39  147445 2015-01-01 01:00:00+00:00 2017-12-30 22:30:00+00:00   \n",
            "34       40  143530 2015-01-01 01:00:00+00:00 2017-12-20 22:30:00+00:00   \n",
            "35       41   59089 2015-01-01 02:00:00+00:00 2017-12-30 23:30:00+00:00   \n",
            "36       42   89174 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "37       44    6865 2015-12-07 12:00:00+00:00 2017-12-30 22:00:00+00:00   \n",
            "38       45   47702 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "39       46   68942 2016-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "40       47   80605 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "41       48   87470 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "42       49   41013 2015-01-01 01:00:00+00:00 2017-12-30 22:00:00+00:00   \n",
            "43       50   54567 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "44       51  181519 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "45       52   10387 2016-01-01 05:55:00+00:00 2017-12-22 19:00:00+00:00   \n",
            "46       55   39754 2015-01-01 05:55:00+00:00 2017-12-30 22:00:00+00:00   \n",
            "47       56   34607 2015-01-01 01:00:00+00:00 2017-12-30 22:00:00+00:00   \n",
            "48       57   54567 2015-01-01 01:00:00+00:00 2017-12-30 22:20:00+00:00   \n",
            "\n",
            "                   td  freq  expected_obs  \n",
            "0  1824 days 21:30:00   NaN           NaN  \n",
            "1  1824 days 21:30:00   NaN           NaN  \n",
            "2  1824 days 21:30:00   NaN           NaN  \n",
            "3  1824 days 21:30:00   NaN           NaN  \n",
            "4  1824 days 21:30:00   NaN           NaN  \n",
            "5  1824 days 21:30:00   NaN           NaN  \n",
            "6  1824 days 21:30:00   NaN           NaN  \n",
            "7  1824 days 21:30:00   NaN           NaN  \n",
            "8  1824 days 21:30:00   NaN           NaN  \n",
            "9  1824 days 21:30:00   NaN           NaN  \n",
            "10 1824 days 21:30:00   NaN           NaN  \n",
            "11 1824 days 21:30:00   NaN           NaN  \n",
            "12 1824 days 21:30:00   NaN           NaN  \n",
            "13 1824 days 21:30:00   NaN           NaN  \n",
            "14 1824 days 21:30:00   NaN           NaN  \n",
            "15 1824 days 21:30:00   NaN           NaN  \n",
            "16 1824 days 21:30:00   NaN           NaN  \n",
            "17 1824 days 21:30:00   NaN           NaN  \n",
            "18 1824 days 21:30:00   NaN           NaN  \n",
            "19 1824 days 21:30:00   NaN           NaN  \n",
            "20 1824 days 21:30:00   NaN           NaN  \n",
            "21 1824 days 21:30:00   NaN           NaN  \n",
            "22 1824 days 21:30:00   NaN           NaN  \n",
            "23 1824 days 21:30:00   NaN           NaN  \n",
            "24 1824 days 21:30:00   NaN           NaN  \n",
            "25 1824 days 21:30:00   NaN           NaN  \n",
            "26 1824 days 21:30:00   NaN           NaN  \n",
            "27 1824 days 21:30:00   NaN           NaN  \n",
            "28 1824 days 21:30:00   NaN           NaN  \n",
            "29 1824 days 21:30:00   NaN           NaN  \n",
            "30 1824 days 21:30:00   NaN           NaN  \n",
            "31 1824 days 21:30:00   NaN           NaN  \n",
            "32 1824 days 21:30:00   NaN           NaN  \n",
            "33 1824 days 21:30:00   NaN           NaN  \n",
            "34 1824 days 21:30:00   NaN           NaN  \n",
            "35 1824 days 21:30:00   NaN           NaN  \n",
            "36 1824 days 21:30:00   NaN           NaN  \n",
            "37 1824 days 21:30:00   NaN           NaN  \n",
            "38 1824 days 21:30:00   NaN           NaN  \n",
            "39 1824 days 21:30:00   NaN           NaN  \n",
            "40 1824 days 21:30:00   NaN           NaN  \n",
            "41 1824 days 21:30:00   NaN           NaN  \n",
            "42 1824 days 21:30:00   NaN           NaN  \n",
            "43 1824 days 21:30:00   NaN           NaN  \n",
            "44 1824 days 21:30:00   NaN           NaN  \n",
            "45 1824 days 21:30:00   NaN           NaN  \n",
            "46 1824 days 21:30:00   NaN           NaN  \n",
            "47 1824 days 21:30:00   NaN           NaN  \n",
            "48 1824 days 21:30:00   NaN           NaN  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>td</th>\n",
              "      <th>freq</th>\n",
              "      <th>expected_obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>95787</td>\n",
              "      <td>2013-01-01 13:00:00+00:00</td>\n",
              "      <td>2017-12-31 10:30:00+00:00</td>\n",
              "      <td>1824 days 21:30:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>95787</td>\n",
              "      <td>2013-01-01 13:00:00+00:00</td>\n",
              "      <td>2017-12-31 10:30:00+00:00</td>\n",
              "      <td>1824 days 21:30:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>95545</td>\n",
              "      <td>2013-01-01 13:00:00+00:00</td>\n",
              "      <td>2017-12-31 10:30:00+00:00</td>\n",
              "      <td>1824 days 21:30:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>95787</td>\n",
              "      <td>2013-01-01 13:00:00+00:00</td>\n",
              "      <td>2017-12-31 10:30:00+00:00</td>\n",
              "      <td>1824 days 21:30:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>95787</td>\n",
              "      <td>2013-01-01 13:00:00+00:00</td>\n",
              "      <td>2017-12-31 10:30:00+00:00</td>\n",
              "      <td>1824 days 21:30:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  count                       min                       max  \\\n",
              "0        2  95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
              "1        3  95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
              "2        4  95545 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
              "3        5  95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
              "4        6  95787 2013-01-01 13:00:00+00:00 2017-12-31 10:30:00+00:00   \n",
              "\n",
              "                  td  freq  expected_obs  \n",
              "0 1824 days 21:30:00   NaN           NaN  \n",
              "1 1824 days 21:30:00   NaN           NaN  \n",
              "2 1824 days 21:30:00   NaN           NaN  \n",
              "3 1824 days 21:30:00   NaN           NaN  \n",
              "4 1824 days 21:30:00   NaN           NaN  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This function count the number of obs you should have if you had a full time sequence\n",
        "Utils.check_length_time_serie(df_weather, date_var, index = id).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "af8a9f1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resample_data: variable temperature\n",
            "resample_data: variable temperature completed\n",
            "resample_data: variable distance\n",
            "resample_data: variable distance completed\n",
            "       timestamp  temperature  site_id   distance\n",
            "0     2015-01-01    -0.038168       51  28.196452\n",
            "1     2015-01-02     1.806015       51  28.194644\n",
            "2     2015-01-03     3.314179       51  28.102067\n",
            "3     2015-01-04     4.661654       51  28.089319\n",
            "4     2015-01-05     5.380741       51  28.615182\n",
            "...          ...          ...      ...        ...\n",
            "61557 2017-12-09          NaN       13        NaN\n",
            "61558 2017-12-10     4.650000       13  25.252279\n",
            "61559 2017-12-11     9.250000       13  24.200407\n",
            "61560 2017-12-12     7.650000       13  25.252279\n",
            "61561 2017-12-13     5.000000       13  24.200407\n",
            "\n",
            "[61562 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Resampling function aggregates data in a dataframe with a chosen function, that can vary depending on the variable\n",
        "# i.e. temperatures when aggregated should be averaged, consumption should be summed, dummy variables should be pick as 'first'\n",
        "\n",
        "df_weather[date_var] = df_weather[date_var].apply(lambda x: x.tz_localize(None))\n",
        "freq = dt.timedelta(days=1)\n",
        "dict_grouping = {'temperature': 'mean', 'distance': 'mean'}\n",
        "df_resampled = Utils.resample_data(df_weather, id, date_var, freq, dict_grouping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e7945831",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>temperature</th>\n",
              "      <th>site_id</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>-0.038168</td>\n",
              "      <td>51</td>\n",
              "      <td>28.196452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-02</td>\n",
              "      <td>1.806015</td>\n",
              "      <td>51</td>\n",
              "      <td>28.194644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-03</td>\n",
              "      <td>3.314179</td>\n",
              "      <td>51</td>\n",
              "      <td>28.102067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-04</td>\n",
              "      <td>4.661654</td>\n",
              "      <td>51</td>\n",
              "      <td>28.089319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-05</td>\n",
              "      <td>5.380741</td>\n",
              "      <td>51</td>\n",
              "      <td>28.615182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   timestamp  temperature  site_id   distance\n",
              "0 2015-01-01    -0.038168       51  28.196452\n",
              "1 2015-01-02     1.806015       51  28.194644\n",
              "2 2015-01-03     3.314179       51  28.102067\n",
              "3 2015-01-04     4.661654       51  28.089319\n",
              "4 2015-01-05     5.380741       51  28.615182"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Regressor dataset do not need a full time sequence to check for NAs\n",
        "df_weather = df_resampled.copy()\n",
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a56ffd2",
      "metadata": {},
      "source": [
        "## Creating working dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6mGY36qeLgvf",
      "metadata": {
        "id": "6mGY36qeLgvf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "# Site Ids available in all data dfs\n",
        "common_site_ids = list(set(df_holidays[id].unique()) & set(df_weather[id].unique()) & set(df_train_data[id].unique()))\n",
        "\n",
        "# Final df\n",
        "df_final = df_train_data[df_train_data[id].isin(common_site_ids)].copy()\n",
        "\n",
        "# Date\n",
        "date_var = Utils.find_date(df_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a5656c",
      "metadata": {},
      "source": [
        "#### Count NAs in y by id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "59ba6bca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>3187477.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>6.370880e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-03</td>\n",
              "      <td>1309542.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.006306e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-04</td>\n",
              "      <td>6998589.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.008557e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-05</td>\n",
              "      <td>5708558.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.017008e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-06</td>\n",
              "      <td>6931527.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.028142e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  timestamp     obs_id  forecast_id         value\n",
              "0       42 2015-11-02  3187477.0       1080.0  6.370880e+05\n",
              "1       42 2015-11-03  1309542.0       1080.0  1.006306e+06\n",
              "2       42 2015-11-04  6998589.0       1080.0  1.008557e+06\n",
              "3       42 2015-11-05  5708558.0       1080.0  1.017008e+06\n",
              "4       42 2015-11-06  6931527.0       1080.0  1.028142e+06"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()\n",
        "#print('List ids in df_final:', list(df_final[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6a3889e4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    site_id  value\n",
              "0        12      0\n",
              "1        13      0\n",
              "2        16      0\n",
              "3        17      0\n",
              "4        18      0\n",
              "5        20      0\n",
              "6        21      0\n",
              "7        22      0\n",
              "8        23      0\n",
              "9        25      0\n",
              "10       26      0\n",
              "11       27      0\n",
              "12       29      0\n",
              "13       32      0\n",
              "14       33      0\n",
              "15       34      0\n",
              "16       39      0\n",
              "17       40      0\n",
              "18       44      0\n",
              "19       45      0\n",
              "20       46      0\n",
              "21       47      0\n",
              "22       48      0\n",
              "23       49      0\n",
              "24       50      0\n",
              "25       51      0\n",
              "26       52      0\n",
              "27       57      0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pivotna = pd.pivot_table(df_final[df_final[y].isna()], index=id, values = y, aggfunc='count').reset_index()\n",
        "pivotna.rename(columns={y: y + '_count_NA'})\n",
        "pivotna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d13842b1",
      "metadata": {},
      "source": [
        "### Creating future values in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5ed8eb62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding sequence to serie 42 as 1 of 29\n",
            "Adding sequence to serie 40 as 2 of 29\n",
            "Adding sequence to serie 25 as 3 of 29\n",
            "Adding sequence to serie 26 as 4 of 29\n",
            "Adding sequence to serie 46 as 5 of 29\n",
            "Adding sequence to serie 47 as 6 of 29\n",
            "Adding sequence to serie 48 as 7 of 29\n",
            "Adding sequence to serie 49 as 8 of 29\n",
            "Adding sequence to serie 50 as 9 of 29\n",
            "Adding sequence to serie 51 as 10 of 29\n",
            "Adding sequence to serie 52 as 11 of 29\n",
            "Adding sequence to serie 12 as 12 of 29\n",
            "Adding sequence to serie 13 as 13 of 29\n",
            "Adding sequence to serie 22 as 14 of 29\n",
            "Adding sequence to serie 23 as 15 of 29\n",
            "Adding sequence to serie 57 as 16 of 29\n",
            "Adding sequence to serie 44 as 17 of 29\n",
            "Adding sequence to serie 45 as 18 of 29\n",
            "Adding sequence to serie 16 as 19 of 29\n",
            "Adding sequence to serie 20 as 20 of 29\n",
            "Adding sequence to serie 21 as 21 of 29\n",
            "Adding sequence to serie 17 as 22 of 29\n",
            "Adding sequence to serie 18 as 23 of 29\n",
            "Adding sequence to serie 27 as 24 of 29\n",
            "Adding sequence to serie 33 as 25 of 29\n",
            "Adding sequence to serie 29 as 26 of 29\n",
            "Adding sequence to serie 32 as 27 of 29\n",
            "Adding sequence to serie 39 as 28 of 29\n",
            "Adding sequence to serie 34 as 29 of 29\n",
            "add_seq: there are NO duplicates in sequence\n",
            "add_seq: there are NO duplicates when adding sequence\n",
            "Total serie to forecast: 75893\n",
            "Latest date 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = Utils.add_seq(df_final, date_var, serie = id, freq = freq, end_date=forecast_end_date, start_date='')\n",
        "print('Latest date', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6740bfb1",
      "metadata": {},
      "source": [
        "### Adding regressors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c112c5",
      "metadata": {},
      "source": [
        "#### Holidays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2830270a",
      "metadata": {},
      "source": [
        "If you don't have specific holiday dataset, you can use the following general function by country that uses the holiday python package and adds to your dataframe a columns with a holiday dummy variable (0/1):\n",
        "\n",
        "    df_final = Regressors.add_holidays_by_country(df_final, date_var, country = 'France')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "805ebacf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['date']\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.merge_holidays_by_date(df_final, df_holidays, id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d3ce6b",
      "metadata": {},
      "source": [
        "#### Site leaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a97e9355",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "dict_days_off = {'friday_is_day_off': 5, 'saturday_is_day_off': 6, 'sunday_is_day_off': 7}\n",
        "df_final = Regressors.merge_additional_days_off(df_final, df_metadata, id, dict_days_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ffa8f25",
      "metadata": {},
      "source": [
        "#### Additional metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "Vr1SWbRb9ZZx",
      "metadata": {
        "id": "Vr1SWbRb9ZZx"
      },
      "outputs": [],
      "source": [
        "df_final = pd.merge(df_final, df_metadata[[id, \"surface\", \"base_temperature\"]], how=\"left\", on=[id], validate = 'm:1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395e6780",
      "metadata": {},
      "source": [
        "#### Other calendar variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "196089f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = Regressors.add_weekdays(df_final, date_var)\n",
        "df_final = Regressors.add_months(df_final, date_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4213c3",
      "metadata": {},
      "source": [
        "#### Weather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f6187177",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.merge_weather(df_final, df_weather, date_var, id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d947c06d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['site_id', 'timestamp', 'obs_id', 'forecast_id', 'value', 'holidays',\n",
              "       'day_off', 'surface', 'base_temperature', 'wd_mon', 'wd_tue', 'wd_wed',\n",
              "       'wd_thu', 'wd_fri', 'wd_sat', 'wd_sun', 'month_01', 'month_02',\n",
              "       'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08',\n",
              "       'month_09', 'month_10', 'month_11', 'month_12', 'temperature',\n",
              "       'distance', 'DDC_temperature', 'DDH_temperature'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final = Regressors.calculate_degree_days(df_final, base_temperature = \"base_temperature\", temperature = \"temperature\")\n",
        "df_final.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6743f041",
      "metadata": {},
      "source": [
        "#### Remove duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fbcb2765",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List ids in df_final after removing duplicates: [12, 13, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 29, 32, 33, 34, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57]\n"
          ]
        }
      ],
      "source": [
        "df_final = df_final.drop_duplicates()\n",
        "print('List ids in df_final after removing duplicates:', list(df_final[id].unique()))\n",
        "assert df_final[df_final.duplicated()].count().sum() == 0, \"y should not contain duplicates\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dff377",
      "metadata": {},
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4715ab4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.to_pickle(os.path.join(root, cfg_path.data_dir.output_path, 'df_final.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "bd0951d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "      <th>holidays</th>\n",
              "      <th>day_off</th>\n",
              "      <th>surface</th>\n",
              "      <th>base_temperature</th>\n",
              "      <th>wd_mon</th>\n",
              "      <th>...</th>\n",
              "      <th>month_07</th>\n",
              "      <th>month_08</th>\n",
              "      <th>month_09</th>\n",
              "      <th>month_10</th>\n",
              "      <th>month_11</th>\n",
              "      <th>month_12</th>\n",
              "      <th>temperature</th>\n",
              "      <th>distance</th>\n",
              "      <th>DDC_temperature</th>\n",
              "      <th>DDH_temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33676.246551</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>3747176.0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>3.870603e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>891.487850</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17.333333</td>\n",
              "      <td>28.407896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2912040.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>2.593093e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1218.738383</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.226667</td>\n",
              "      <td>21.793645</td>\n",
              "      <td>6.226667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1625.837520</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>18</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>677.533195</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  timestamp     obs_id  forecast_id         value  holidays  \\\n",
              "0       12 2015-11-02        NaN          NaN           NaN         0   \n",
              "1       13 2015-11-02  3747176.0        415.0  3.870603e+06         1   \n",
              "3       16 2015-11-02  2912040.0        524.0  2.593093e+06         1   \n",
              "5       17 2015-11-02        NaN          NaN  0.000000e+00         1   \n",
              "7       18 2015-11-02        NaN          NaN  0.000000e+00         1   \n",
              "\n",
              "   day_off       surface  base_temperature  wd_mon  ...  month_07  month_08  \\\n",
              "0        0  33676.246551              18.0       1  ...         0         0   \n",
              "1        0    891.487850              18.0       1  ...         0         0   \n",
              "3        0   1218.738383              18.0       1  ...         0         0   \n",
              "5        0   1625.837520              18.0       1  ...         0         0   \n",
              "7        0    677.533195              18.0       1  ...         0         0   \n",
              "\n",
              "   month_09  month_10  month_11  month_12  temperature   distance  \\\n",
              "0         0         0         1         0          NaN        NaN   \n",
              "1         0         0         1         0    17.333333  28.407896   \n",
              "3         0         0         1         0    24.226667  21.793645   \n",
              "5         0         0         1         0          NaN        NaN   \n",
              "7         0         0         1         0          NaN        NaN   \n",
              "\n",
              "   DDC_temperature  DDH_temperature  \n",
              "0              NaN              NaN  \n",
              "1         0.000000         0.666667  \n",
              "3         6.226667         0.000000  \n",
              "5              NaN              NaN  \n",
              "7              NaN              NaN  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())\n",
        "df_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03d735c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AbKOiffyAql8",
        "6YxUycDC9p0h"
      ],
      "name": "Analysis (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
